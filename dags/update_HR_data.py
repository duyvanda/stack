# -*- coding: utf-8 -*-
"""f_sales_pend.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gv4TJMgxnLP4CFit3NFDFF8kjnBH9Ci6
"""

# # DON'T USE THIS CELL
from utils.df_handle import *
import pendulum
from airflow import DAG
from airflow.operators.dummy_operator import DummyOperator
from airflow.operators.python_operator import PythonOperator
import io
import shutil
from google.oauth2 import service_account
from googleapiclient import discovery
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
from cmath import nan

local_tz = pendulum.timezone("Asia/Bangkok")
name='hr_data'
prefix='update_'
path = f'/usr/local/airflow/plugins/update_hr_data/'#--{prefix}{name}/'

# datenow_min1 = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")

dag_params = {
    'owner': 'phuonght2',
    "depends_on_past": False,
    'start_date': datetime(2022, 4, 28, tzinfo=local_tz),
    # 'email_on_failure': True,
    # 'email_on_retry': False,
    # 'email':['duyvq@merapgroup.com', 'vanquangduy10@gmail.com'],
    'do_xcom_push': False,
    'execution_timeout':timedelta(seconds=300)
    # 'retries': 3,
    # 'retry_delay': timedelta(minutes=10),
}

dag = DAG(prefix+name,
          catchup=False,
          default_args=dag_params,
          schedule_interval= '0 8-23 * * *',
          tags=[prefix+name, 'Daily', '60mins']
)

# fdom = datetime.now().replace(day=1).strftime("%Y%m%d")
# datenow = datetime.now().strftime("%Y%m%d")
# datenow_add1 = (datetime.now() + timedelta(1)).strftime("%Y%m%d")

def load_hr_data():
    scopes = ['https://www.googleapis.com/auth/spreadsheets', 
            'https://www.googleapis.com/auth/drive',
            'https://www.googleapis.com/auth/drive.file']
    jsonfile = path+'datateam.json'
    credentials = service_account.Credentials.from_service_account_file(jsonfile, scopes=scopes)
    service = discovery.build('drive', 'v3', credentials=credentials)


    file_id = '1EmMS46usylDzxDrKzteFQk2XzlZEMGpD'

    fh = io.BytesIO()

    request = service.files().get_media(fileId=file_id)

    downloader = MediaIoBaseDownload(fh, request, chunksize=204800)

    done = False

    datenow = datetime.now().strftime("%Y%m%d")

    while not done:
        status, done = downloader.next_chunk()

    fh.seek(0)
    with open(path+f"{datenow}_"+"DSNS_PN-MRTD.xlsx", 'wb') as f:
                    shutil.copyfileobj(fh, f)

# def update_hr_data():
    #láº¥y data hr
    df_thongtin = pd.read_excel(path+f"{datenow}_"+"DSNS_PN-MRTD.xlsx",sheet_name='DS Tong MN')
    df_nghiviec= pd.read_excel(path+f"{datenow}_"+"DSNS_PN-MRTD.xlsx",sheet_name='NGHI VIEC')
    df_biendong = pd.read_excel(path+f"{datenow}_"+"DSNS_PN-MRTD.xlsx",sheet_name='Theo doi bien dong')

    print("Done convert to df")

    lst_df = [df_thongtin,df_nghiviec,df_biendong]
    for i in lst_df:
        cleancols(i)
        i.columns = lower_col(i)



    # df_thongtin['ngaynghiviecdieuchuyen'] = np.where(df_thongtin['ngaynghiviecdieuchuyen'].str.contains("TS"), nan, df_thongtin['ngaynghiviecdieuchuyen'])
    lst = ['ngayvaolamviec','ngaythangnamsinh','ngaycap', 'tungay','denngay','ngayketthucthuviec','ngaynghiviecdieuchuyen']
    for i in lst:
        print("df_thongtin 1", i)
        df_thongtin[i]= pd.to_datetime(df_thongtin[i], utc=True)
        
    lst = ['ngayvaolamviec','ngaythangnamsinh', 'tungay','ngayketthucthuviec','ngaynghiviec']
    for i in lst:
        print("df_nghiviec 1", i)
        df_nghiviec[i]= pd.to_datetime(df_nghiviec[i].astype(str), utc=True)
        

    lst = ['ngaycap','denngay'] 
    for i in lst:
        print("df_nghiviec 2", i)
        df_nghiviec[i]= pd.to_datetime(df_nghiviec[i], utc=True)
        
    
    lst = ['ngayvaolamviec','thoigianapdung']
    for i in lst:
        print("df_biendong", i)
        df_biendong[i]= pd.to_datetime(df_biendong[i], utc=True)
        

    # print("df_biendong ['ngayvaolamviec','thoigianapdung'] ")


    lst = ['cmnd','solanhdlddaky', 'sosobh','sl', 'ngaysn','thangsn','namsn','tuoi','masothue','bophange','phanloainghiviec','ghichutinhhinhnhansunghiviec','ghichu']
    df_nghiviec[lst]= df_nghiviec[lst].astype('str')

    lst = ['bophange','solanhdlddaky','sl','phanloainghiviec','ghichutinhhinhnhansunghiviec','ngaysn','thangsn','namsn','cmnd','masothue']
    df_thongtin[lst]= df_thongtin[lst].astype('str')
    df_thongtin['stt'].fillna(0,inplace=True)
    df_thongtin['tuoi'].fillna(0,inplace=True)

    lst = ['stt','ghichu']
    df_biendong[lst]= df_biendong[lst].astype('str')
    a = service.files().get(fileId='1EmMS46usylDzxDrKzteFQk2XzlZEMGpD', fields='modifiedTime,name').execute()



    for i in lst_df:
        i.fillna("",inplace=True)
        i['inserted_at']=datetime.now()
        i['file']=a['name']
        i['last_updated']=pd.to_datetime(a['modifiedTime'])


    bq_values_insert(df_thongtin, "d_hr_thongtincanhan",3)
    bq_values_insert(df_nghiviec, "d_hr_dsnghiviec",3)
    bq_values_insert(df_biendong, "d_hr_biendong",3)

        


# Dont Execute this
dummy_start = DummyOperator(task_id="dummy_start", dag=dag)

load_hr_data = PythonOperator(task_id="load_hr_data", python_callable=load_hr_data, dag=dag)


# update_hr_data = PythonOperator(task_id="update_hr_data", python_callable=update_hr_data, dag=dag)

dummy_start >> load_hr_data 